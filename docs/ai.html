<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-0.9.318">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Modesto Redrejo Rodríguez">
<meta name="dcterms.date" content="2022-07-18">

<title>Hands-on protein modeling - State-of-the-art protein modeling with Colabfold</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link id="quarto-text-highlighting-styles" href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


</head>

<body class="floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Hands-on protein modeling</span>
  </a>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html">Home</a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./intro.html">Introduction</a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./homology.html">Homology modeling</a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="./ai.html" aria-current="page">AI-based modeling</a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#how-did-we-get-to-the-era-of-alphafold-rel." id="toc-how-did-we-get-to-the-era-of-alphafold-rel." class="nav-link active" data-scroll-target="#how-did-we-get-to-the-era-of-alphafold-rel.">How did we get to the Era of Alphafold (&amp; rel.)?</a>
  <ul class="collapse">
  <li><a href="#the-recent-history-of-protein-structure-modeling-telling-by-a-contest-casp" id="toc-the-recent-history-of-protein-structure-modeling-telling-by-a-contest-casp" class="nav-link" data-scroll-target="#the-recent-history-of-protein-structure-modeling-telling-by-a-contest-casp">The recent history of protein structure modeling telling by a contest (CASP)</a></li>
  </ul></li>
  <li><a href="#casp14-or-when-protein-structure-prediction-come-to-age-for-non-structural-biologists" id="toc-casp14-or-when-protein-structure-prediction-come-to-age-for-non-structural-biologists" class="nav-link" data-scroll-target="#casp14-or-when-protein-structure-prediction-come-to-age-for-non-structural-biologists">CASP14 or when protein structure prediction come to age for non structural biologists</a>
  <ul class="collapse">
  <li><a href="#why-is-alphafold2-so-freaking-accurate" id="toc-why-is-alphafold2-so-freaking-accurate" class="nav-link" data-scroll-target="#why-is-alphafold2-so-freaking-accurate">Why is Alphafold2 so freaking accurate?</a></li>
  <li><a href="#lets-try-alphafold2." id="toc-lets-try-alphafold2." class="nav-link" data-scroll-target="#lets-try-alphafold2.">Let’s try Alphafold2.</a></li>
  <li><a href="#corollary-has-levinthals-paradox-folded" id="toc-corollary-has-levinthals-paradox-folded" class="nav-link" data-scroll-target="#corollary-has-levinthals-paradox-folded">Corollary: Has Levinthal’s paradox “folded”?</a></li>
  </ul></li>
  <li><a href="#links" id="toc-links" class="nav-link" data-scroll-target="#links">Useful links</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">State-of-the-art protein modeling with Colabfold</h1>
</div>





<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Modesto Redrejo Rodríguez </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">July 18, 2022</p>
    </div>
  </div>
    
  </div>
  

</header>

<section id="how-did-we-get-to-the-era-of-alphafold-rel." class="level1">
<h1>How did we get to the Era of Alphafold (&amp; rel.)?</h1>
<p>As mentioned earlier, the introduction of HMM-based profiles during the first decade of this century led to a great improvement in template detection and protein modeling in the twilight zone, i.e., proteins with only distant homologs (&lt;25-30% identity) in databases. These methods naturally evolved into iterative <u>threading</u> methods, based on multitemplate model construction, implemented in <a href="https://zhanggroup.org/I-TASSER/">I-TASSER</a> <span class="citation" data-cites="roy2010">(<a href="#ref-roy2010" role="doc-biblioref">Roy, Kucukural, and Zhang 2010</a>)</span>, <a href="http://raptorx.uchicago.edu/">RaptorX</a> [<span class="citation" data-cites="peng2011">Peng and Xu (<a href="#ref-peng2011" role="doc-biblioref">2011</a>)</span>], and <a href="https://toolkit.tuebingen.mpg.de/tools/hhpred">HHpred</a> <span class="citation" data-cites="meier2015">(<a href="#ref-meier2015" role="doc-biblioref">Meier and Söding 2015</a>)</span>, among others. We are not going to discuss these methods by lack of time and because they are currently somewhat disused as Alphafold2 captures all the attention, and we will move to the very last advancements. I advise checking the provided references and the <a href="#links">Useful links</a> below for a more accurate and comprehensive discussion on deep learning-fueled protein modeling.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<figure class="figure">
<img src="pics/contact.png" title="Contact-based map" class="img-fluid figure-img">
</figure>
<p></p><figcaption aria-hidden="true" class="figure-caption">Contact-based map of representative proteins. The map represents a matrix of amino acid positions in the protein sequences (on both, the X and Y axis); with contacts indicated as blue dots. When a number of consecutive residues in the sequence interact the dots form diagonal stretches. Maps obtained at <a href="http://cmweb.enzim.hu/" class="uri">http://cmweb.enzim.hu/</a></figcaption><p></p>
</figure>
</div>
<p>During the last decade, the introduction of <strong>residue-residue contact or distance maps</strong> prediction based on sequence co-evolution and <em>deep learning</em> started a revolution in the field that crystallize with the arrival of Alphafold2 and RoseTTAfold as major breakthroughs with great repercussions in diverse fields.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="pics/coevolution.webp" class="img-fluid figure-img"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Schematic of how co-evolution methods extract information about protein structure from a multiple sequence alignment (MSA). Image modified from doi: <code>10.5281/zenodo.1405369</code>, which in turn was modified from doi: <code>10.1371/journal.pone.0028766</code></figcaption><p></p>
</figure>
</div>
<p>As shown in the picture below, residue contact maps are a 2D matrix-like representation of the protein sequence in which each pair of interacting residues are indicated. An accurate information of protein’s residue–residue contacts is sufficient to elucidate the fold of a protein <span class="citation" data-cites="olmea1997">(<a href="#ref-olmea1997" role="doc-biblioref">Olmea and Valencia 1997</a>)</span>; however predicting that map is not always easy. The introduction of <strong>evolutionary coupling analysis (ECA)</strong>, i.e., extract the residue coevolution from MSAs (piture above) improved contact maps and allowed their implementation for protein folding in several methods, like PSICOV [<span class="citation" data-cites="jones2012">Jones et al. (<a href="#ref-jones2012" role="doc-biblioref">2012</a>)</span>] or Gremlin <span class="citation" data-cites="kamisetty2013">(<a href="#ref-kamisetty2013" role="doc-biblioref">Kamisetty, Ovchinnikov, and Baker 2013</a>)</span>, among others. However, for proteins without many sequence homologs, the predicted contacts were of low quality and insufficient for accurate contact-assisted protein modeling.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="pics/contact2.gif" class="img-fluid figure-img"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Illustration of column pair and precision submatrix grouping for advanced prediction of contact maps. In the example, Columns 5 and 14 in the first family are aligned to columns 5 and 11 in the second family, respectively, so column pair (5,14) in the first family and the pair (5,11) in the second family are assigned to the same group. Accordingly, the two precision submatrices will be asigned to the same group. From <span class="citation" data-cites="ma2015">Ma et al. (<a href="#ref-ma2015" role="doc-biblioref">2015</a>)</span>.</figcaption><p></p>
</figure>
</div>
<p>Deep learning is a sub-field of machine learning which is based on artificial neural networks (NN). Neural networks were introduced actually in the late 40’s and 50’s, but they reappeared in the 2000’s thanks to the increase of computational capacities and, more recently, the use of <a href="https://en.wikipedia.org/wiki/Graphics_processing_unit">GPUs</a>. Briefly, a NN uses multiple interconnected layers to transform multiple inputs (MSAs, high-resolution contact based maps…) into compound features that can be used to predict a complex output, like a 3D protein structure. As their name indicate, NNs attempt to simulate the behavior of the human brain that process large amounts of data and can be trained to “learn” from that data. Deep learning is based in the use of multiple layer-NN to optimize and refine for accuracy.</p>
<p>In this context, introduction of supervised machine learning methods that predict contacts from distant protein families, outperforming ECA methods by the use of multilayer neural networks [<span class="citation" data-cites="jones2015">Jones et al. (<a href="#ref-jones2015" role="doc-biblioref">2015</a>)</span>, <span class="citation" data-cites="ma2015">Ma et al. (<a href="#ref-ma2015" role="doc-biblioref">2015</a>)</span>]. These methods allowed the use of the so-called high resolution contact maps, that contained not only contact information, but also probabilities, distances and angles.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<figure class="figure">
<img src="pics/high_res_maps.png" title="High-resolution contact maps" class="img-fluid figure-img">
</figure>
<p></p><figcaption aria-hidden="true" class="figure-caption">Example of high-resolution contact maps of 6MSP. From <span class="citation" data-cites="yang2020">Yang et al. (<a href="#ref-yang2020" role="doc-biblioref">2020</a>)</span></figcaption><p></p>
</figure>
</div>
<section id="the-recent-history-of-protein-structure-modeling-telling-by-a-contest-casp" class="level2">
<h2 class="anchored" data-anchor-id="the-recent-history-of-protein-structure-modeling-telling-by-a-contest-casp">The recent history of protein structure modeling telling by a contest (CASP)</h2>
<p>Every two years since 1994, structural bioinformatics groups carry out a worldwide experiment, predicting a set of unknown protein structures in a controlled, blind-test-like competition and comparing their output with the experimentally obtained structure. This is the <strong>CASP</strong> or <a href="https://predictioncenter.org/"><em>Critical assessment of Protein Structure Prediction</em></a>.</p>
<div id="fig-anonymous-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><a href="https://predictioncenter.org/casp13/zscores_final.cgi?formula=gdt_ts"><img src="pics/casp13.png" title="CASP13 results" class="img-fluid figure-img"></a></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Comparative z-core of CASP13 participants. The score is based in the GDT_TS (Global distance test).</figcaption><p></p>
</figure>
</div>
<p>The best research groups in the field test their new methods and protocols in CASP. However, in CASP13 (2018) an AI company called <a href="https://en.wikipedia.org/wiki/DeepMind">Deepmind</a> (Google Subsidiary) entered in the scene. Their method, named Alphafold <span class="citation" data-cites="senior2020">(<a href="#ref-senior2020" role="doc-biblioref">Senior et al. 2020</a>)</span> clearly won CASP13. Alphafold implemented some improvements in a few recently used approaches, creating a new whole pipeline. Basically, instead of create contact maps from the alignment to then fold the structure, they used a MRF unit (Markov Random Field) to extract in advance the main features of sequence and the MSA and process all of that info into a multilayer NN (called ResNet) that provides the distant map and other information. Then, Alphafold uses all the possibly obtained information to create the structure and then improve it by energy minimization and substitution of portions with a selected DB of protein fragments.</p>
<div id="fig-anonymous-2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><a href="https://docs.google.com/presentation/d/1mnffk23ev2QMDzGZ5w1skXEadTe54l8-Uei6ACce8eI"><img src="pics/alphafold1.png" title="Alphafold1" class="img-fluid figure-img"></a></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Workflow of the first Alphafold method presented in CASP13. MSA stands for multiple sequence alignment; PSSM indicates Position-specific-scoring matrix and MRF stands for Markov Random Field (or Potts model). From the Sergei Ovchinnikov and Martin Steinegger presentation of Alphafold2 to the Boston Protein Design Group (link below)</figcaption><p></p>
</figure>
</div>
<p>After Alphafold, similar methods were also developed and made available to the general public, like the <em>trRosetta</em> from Baker lab <span class="citation" data-cites="yang2020">(<a href="#ref-yang2020" role="doc-biblioref">Yang et al. 2020</a>)</span>, available in the <a href="https://robetta.bakerlab.org/">Robetta</a> server. This led to some controversy (mostly on Twitter) about the open access to the CASP software and later on DeepMind publishes all the code on GitHub.</p>
</section>
</section>
<section id="casp14-or-when-protein-structure-prediction-come-to-age-for-non-structural-biologists" class="level1">
<h1>CASP14 or when protein structure prediction come to age for non structural biologists</h1>
<p>In CASP14 the expectation was very high and the guys from DeepMind did not disappoint anyone. Alphafold2 highly outperformed all competitors, both in relative (score respect the other groups) and absolute terms (lowest alpha-C RMSD). As has been highlighted, the accuracy of many of the predicted structures was within the error margin of experimental determination methods <span class="citation" data-cites="mirdita2022">(see for instance <a href="#ref-mirdita2022" role="doc-biblioref">Mirdita et al. 2022</a>)</span>.</p>
<div id="fig-anonymous-3" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><a href="https://predictioncenter.org/casp14/zscores_final.cgi?formula=gdt_ts"><img src="pics/casp14.png" title="CASP14 scores" class="img-fluid figure-img"></a></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Comparative CASP14 scores</figcaption><p></p>
</figure>
</div>
<div id="fig-anonymous-4" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><a href="https://www.nature.com/articles/s41586-021-03819-2/figures/1"><img src="pics/jumper2021.png" title="Alphafold2" class="img-fluid figure-img"></a></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Performance of Alphafold2 the CASP14 dataset relative to the top-15 entries. Data are median and the 95% confidence interval of the median, for alpha-carbom RMSD. Panels b-c-d show example comparison between model and experimental structures.</figcaption><p></p>
</figure>
</div>
<p>Alphafold took some time (eight months, an eternity nowadays) to publish the method (<span class="citation" data-cites="jumper2021">Jumper et al. (<a href="#ref-jumper2021" role="doc-biblioref">2021</a>)</span>) and making it available on <a href="https://github.com/deepmind/alphafold">Github</a>, but other new methods, like RoseTTAfold (<span class="citation" data-cites="baek2021">Baek et al. (<a href="#ref-baek2021" role="doc-biblioref">2021</a>)</span>) and C-I-Tasser (<span class="citation" data-cites="zheng2021">Zheng et al. (<a href="#ref-zheng2021" role="doc-biblioref">2021</a>)</span>) could reproduce their results and were available on public servers, which may have push Deepmind to make everything available to the scientific community (see the Grace Huckins’ <a href="https://www.wired.com/story/without-code-for-deepminds-protein-ai-this-lab-wrote-its-own/">article</a> on Wired). Not surprisingly (at least for me), a group of independent scientists (<a href="https://twitter.com/sokrypton">Sergey Ovchinnikov</a>, <a href="https://twitter.com/milot_mirdita">Milot Mirdita</a>, and <a href="https://twitter.com/thesteinegger">Martin Steinegger</a>), decided to implement Alphafold2 in a <a href="https://github.com/sokrypton/ColabFold">Colab notebook</a>, named ColabFold <span class="citation" data-cites="mirdita2022">Mirdita et al. (<a href="#ref-mirdita2022" role="doc-biblioref">2022</a>)</span>, freely available online. Other free implementations of Alphafold have been and are available, but ColabFold has been the most widely discussed and known. They implemented some tricks to accelerate the modeling, mainly the use of <a href="https://docs.google.com/presentation/d/1mnffk23ev2QMDzGZ5w1skXEadTe54l8-Uei6ACce8eI/present#slide=id.ge58c80b745_0_15">MMSeqs2</a> (developed by Martin Steinegger’s group) to search for homolog structures on Uniref30, which made Colabfold a quick method that made all the previous advanced methods almost useless. This was the real breakthrough in the protein structure field, making Alphafold2 available to every one and, also very important, facilitate the evolution of the method, implementing new features, like the prediction of protein complexes ( <span class="citation" data-cites="evans2022">Evans et al. (<a href="#ref-evans2022" role="doc-biblioref">2022</a>)</span>), which was actually mentioned first on <a href="https://docs.google.com/presentation/d/1mnffk23ev2QMDzGZ5w1skXEadTe54l8-Uei6ACce8eI/present#slide=id.ge58c80b745_0_15">Twitter</a>.</p>
<section id="why-is-alphafold2-so-freaking-accurate" class="level2">
<h2 class="anchored" data-anchor-id="why-is-alphafold2-so-freaking-accurate">Why is Alphafold2 so freaking accurate?</h2>
<p>The philosophy behind Alphafold and related methods is treating the protein folding problem as a machine learning problem, kind of of image processing. In all these problems, the input to the Deep Learning model is a volume (3D tensor). In the case of computer vision, 2D images expand as a volume because of the RGB or HSV channels. Similarly, in the case of distance prediction, predicted 1D and 2D features are transformed and packed into 3D volume with many channels of inter-residue information <span class="citation" data-cites="pakhrin2021">(<a href="#ref-pakhrin2021" role="doc-biblioref">Pakhrin et al. 2021</a>)</span>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="pics/machine_fold.png" class="img-fluid figure-img"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">From the perspective of Deep Learning method development, the problem of protein distogram or real-valued distance prediction (bottom row) is similar to the ‘depth prediction problem’ in computer vision. From <span class="citation" data-cites="pakhrin2021">Pakhrin et al. (<a href="#ref-pakhrin2021" role="doc-biblioref">2021</a>)</span>.</figcaption><p></p>
</figure>
</div>
<p>Alphafold2 can be explained as a pipeline with three interconected tasks (see picture below). First, it queries several databases of protein sequences and constructs an MSA that is used to select templates. In the second part of the diagram, AlphaFold 2 takes the multiple sequence alignment and the templates, and processes them in a <em>transformer</em>. This process has been referred by some authors as inter-residue interaction map-threading <span class="citation" data-cites="bhattacharya2021">(<a href="#ref-bhattacharya2021" role="doc-biblioref">Bhattacharya et al. 2021</a>)</span>. The objective of this part is to extract layers of information to generate residue interaction maps. A better model of the MSA will improve the network’s characterization of the geometry, which simultaneously will help refine the model of the MSA. Importantly, in the AF2 Evoformer, this process is iterative and the information goes back and forth throughout the network. At every recycling step, the complexity of the map increases and thus, the model improves (the original model uses 3 cycles). As explained in the great <a href="https://www.blopig.com/blog/2021/07/alphafold-2-is-here-whats-behind-the-structure-prediction-miracle/">post</a> from Carlos Outerial at the OPIG site:</p>
<blockquote class="blockquote">
<p><em>This is easier to understand as an example. Suppose that you look at the multiple sequence alignment and notice a correlation between a pair of amino acids. Let’s call them A and B. You hypothesize that A and B are close, and translate this assumption into your model of the structure. Subsequently, you examine said model and observe that, since A and B are close, there is a good chance that C and D should be close. This leads to another hypothesis, based on the structure, which can be confirmed by searching for correlations between C and D in the MSA. By repeating this several times, you can build a pretty good understanding of the structure.</em></p>
</blockquote>
<p>The third part of the pipeline is the structure building module, which uses the information from the previous steps to construct a 3D model structure protein of the query sequence. This network will give you a single model, without any energy optimization step. Model building is based in a new concept of 3D structures generation, named IPA (Invariant Point Attention) and the use of a curated list of parametrised list of torsion angles to generate the side chains.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<figure class="figure">
<img src="pics/alphafols2.png" title="Alphafold2" class="img-fluid figure-img">
</figure>
<p></p><figcaption aria-hidden="true" class="figure-caption">Oxford Proteins Informatics Group Blog, modified From</figcaption><p></p>
</figure>
</div>
<p>Like for most of the previous methods Alphafold would give your better results with proteins with related structures known and with a lot of homologs in Uniref databases. However, comparing to nothing, it will likely give you (limited) useful results for the so-called “dark genome”. I work with phages and bacterial mobile elements, and sequencing that is often frustrating as more than 50% of the proteins have no homologs in the database. So you have a bunch of proteins of unknown function… However, as we do know that structure is more conserved than sequence, we may use the structure to find out the function of our dark proteins. There are a few resources for this, I’d suggest you to try <a href="https://search.foldseek.com/search">FoldSeek</a> [<span class="citation" data-cites="kempen">Kempen et al. (<a href="#ref-kempen" role="doc-biblioref">n.d.</a>)</span>] and <a href="http://ekhidna2.biocenter.helsinki.fi/dali/">Dali</a> [<span class="citation" data-cites="holm2022">Holm (<a href="#ref-holm2022" role="doc-biblioref">2022</a>)</span>] servers. You can upload the PDB of your model and search for related structures in PDB and also in Alphafold database.</p>
<p>As mentioned above, Colabfold aims to make the process faster by using MMSeqs in the first block. Additionally, the number of recycling steps can also be adapted. Moreover, different Colabfold notebooks have been developed (and evolved) to allow some customization and other feature, like batch processing of multiple proteins avoiding recompilation and identification of protein-protein interactions <span class="citation" data-cites="mirdita2022">(<a href="#ref-mirdita2022" role="doc-biblioref">Mirdita et al. 2022</a>)</span>.</p>
<p>Alphafold models can be evaluated by the mean <strong>pLDDT</strong>, a per-residue confidence metric. The model confidence can vary greatly along a chain so it is important to consult the confidence when interpreting structural features. Very often, the lower confidence fragments are not product of a poor prediction but an indicator of protein disorder.</p>
<p>Alphafold also partnered with EMBL-EBI and Uniprot and generated a huge curated database of proteins from model organisms [<span class="citation" data-cites="varadi2022">Varadi et al. (<a href="#ref-varadi2022" role="doc-biblioref">2022</a>)</span>], the <a href="https://alphafold.ebi.ac.uk/">Alphafold database</a>. This is an amazing resource that may be also very helpful for you. Just consider that this database increased from 48% to 76% the fraction of human proteome with structural data, and also it also means great increases in the case of other model organisms, like, including microorganisms and plants <span class="citation" data-cites="porta-pardo2022">(<a href="#ref-porta-pardo2022" role="doc-biblioref">Porta-Pardo et al. 2022</a>)</span>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<figure class="figure">
<img src="pics/journal.pcbi.1009818.g004.PNG" title="Changes in protein structural coverage in model organisms." class="img-fluid figure-img">
</figure>
<p></p><figcaption aria-hidden="true" class="figure-caption">Changes in protein structural coverage in model organisms.</figcaption><p></p>
</figure>
</div>
</section>
<section id="lets-try-alphafold2." class="level2">
<h2 class="anchored" data-anchor-id="lets-try-alphafold2.">Let’s try Alphafold2.</h2>
<p>Section under construction!</p>
<p>As mentioned above, the grand breakthrough of Alphafold would not have been the same without the Colabfold, a free open tool that made the state-of-the-art of AI-fueled protein prediction available to everyone.</p>
<div id="fig-anonymous-5" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><a href="https://github.com/sokrypton/ColabFold"><img src="pics/qrcode.png" title="ColabFold" class="img-fluid figure-img" width="441"></a></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">ColabFold GitHub repository</figcaption><p></p>
</figure>
</div>
<p>The Colabfold repository on GitHub contains links to several Python “notebooks” developed on <a href="https://colab.research.google.com/">Google Colab</a>, a platform to develop and share Python scripts on a Jupyter Notebook format. Notebooks are very important also for reproducibility in computer sciences, as they allow you to have the background and details and the actual code in a single document and also execute it. You can share those notebooks very easily and also update quickly as they are stored in your Google Drive.</p>
<p>Colabfold allow you to run notebooks of Alphafold and RoseTTAfold for specific applications, allowing even to run a bunch of proteins in batch. You can see a more detailed description in <span class="citation" data-cites="mirdita2022">Mirdita et al. (<a href="#ref-mirdita2022" role="doc-biblioref">2022</a>)</span>. We are using the <a href="https://colab.research.google.com/github/sokrypton/ColabFold/blob/main/AlphaFold2.ipynb">Alphafold2_mmseqs2</a> notebook, that allow you most of the common features. You need to allow Colab to use your Google account.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<figure class="figure">
<img src="pics/colab1.jpg" title="Input sequence" class="img-fluid figure-img">
</figure>
<p></p><figcaption aria-hidden="true" class="figure-caption">Introducing your sequence in Colabfold</figcaption><p></p>
</figure>
</div>
<p>Then paste your sequence and chose a name. For more accurate models you can click “use_amber” option. It will run a short <a href="https://en.wikipedia.org/wiki/Molecular_dynamics"><em>Molecular Dynamics</em></a> protocol that ultimately optimize the modeling, but it will also take some more time, so better try at home.</p>
<p>As you can see, an this is a recent feature, you can also add your own template. That will safe time, but of course without any guarantee. If you have a template of a related protein, like an alternative splicing or a disease mutant, I’d advise you to try with and without the template. You may surprise.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="pics/colab_execute.jpg" class="img-fluid figure-img"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Executing Colabfold</figcaption><p></p>
</figure>
</div>
<p>At this point, you may execute the whole pipeline or may some more customization. MSA stage can be also optimized to reduce execution time, by reducing database or even by providing your own MSA. Very often you may want to fold a protein with different parameters, particularly in the <a href="https://colab.research.google.com/github/sokrypton/ColabFold/blob/main/beta/AlphaFold2_advanced.ipynb#scrollTo=rowN0bVYLe9n">Advanced Colabfold</a>, which may very convenient to reuse an MSA from a previous run (although they recently updated servers for MMSeqs and made it really faster). If your proteins are in the same operon or by any other reason you think that they should have co-evolved, you prefer a “paired” alignment. But you can always do both.</p>
<p>Advanced settings are specially needed for protein-protein complexes. Also the number of recycling steps will improve your model, particularly for targets with no MSA info from used databases. Then you can just get your model (and companion info and plots) in your GDrive or download it.</p>
<p><span style="color:green"><strong>What do you think is the ideal protein for alphafold2? Do you think homology modeling is dead?</strong></span></p>
</section>
<section id="corollary-has-levinthals-paradox-folded" class="level2">
<h2 class="anchored" data-anchor-id="corollary-has-levinthals-paradox-folded">Corollary: Has Levinthal’s paradox “folded”?</h2>
<p>The development of Alphafold and the <a href="https://alphafold.ebi.ac.uk/">Alphafold structures Database</a> in collaboration with <a href="https://www.ebi.ac.uk/about">EMBL-EBI</a> has been the origin of a New Era. Scientific publications and journals worldwide published long articles about the meaning of this breakthrough in science and its applications in biotechnology and biomedicine<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> and DeepMind claimed to have <a href="https://www.deepmind.com/blog/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology">Solved a 50-years Grand Challenge in biochemistry</a>. The coverage of the protein structure space has been greatly increased <span class="citation" data-cites="porta-pardo2022">(<a href="#ref-porta-pardo2022" role="doc-biblioref">Porta-Pardo et al. 2022</a>)</span>.</p>
<p>However, some scientists have claimed that Alphafold2 and RoseTTAfold actually “cheat” a bit as it does not really solve the problem but generate a deep learning pipeline that “bypass” the problem <span class="citation" data-cites="pederson2021">(<a href="#ref-pederson2021" role="doc-biblioref">Pederson 2021</a>)</span>. In agreement with that, it has been shown that machine learning methods actually do not reproduce the expected folding pathways while improving the structures during the recycling steps <span class="citation" data-cites="outeiral">Outeiral, Nissley, and Deane (<a href="#ref-outeiral" role="doc-biblioref">n.d.</a>)</span>.</p>
<p>In conclusion, I do believe that Levinthal’s paradox has not been (yet) fully solved, but clearly almost <span class="citation" data-cites="al-janabi2022">(<a href="#ref-al-janabi2022" role="doc-biblioref">Al-Janabi 2022</a>)</span>, and solving it will probably reduce the limitations of Alphafold2. However, <a href="https://predictioncenter.org/casp15/index.cgi">CASP15</a> is currently being held and maybe I will have to change my mind later this year.</p>
</section>
</section>
<section id="links" class="level1">
<h1>Useful links</h1>
<ul>
<li><p>Introductory article to Neural Networks at the IBM site: <a href="https://www.ibm.com/cloud/learn/neural-networks" class="uri">https://www.ibm.com/cloud/learn/neural-networks</a></p></li>
<li><p>ColabFold Tutorial presented presented by Sergey Ovchinnikov and Martin Steineggerat the Boston Protein Design and Modeling Club (6 ago 2021). <a href="https://www.youtube.com/watch?v=Rfw7thgGTwI">[video]</a> <a href="https://docs.google.com/presentation/d/1mnffk23ev2QMDzGZ5w1skXEadTe54l8-Uei6ACce8eI">[slides]</a>.</p></li>
<li><p>Post about Alphafold2 in the Oxford Protein Informatics Group site: <a href="https://www.blopig.com/blog/2021/07/alphafold-2-is-here-whats-behind-the-structure-prediction-miracle/" class="uri">https://www.blopig.com/blog/2021/07/alphafold-2-is-here-whats-behind-the-structure-prediction-miracle/</a></p></li>
<li><p>A very good digest article about the Alphafold2 paper: <a href="https://moalquraishi.wordpress.com/2021/07/25/the-alphafold2-method-paper-a-fount-of-good-ideas/" class="uri">https://moalquraishi.wordpress.com/2021/07/25/the-alphafold2-method-paper-a-fount-of-good-ideas/</a></p></li>
<li><p>Post on the Alphafold2 revolution meaning in biomedicine at the the UK Institute for Cancer Research website: <a href="https://www.icr.ac.uk/blogs/the-drug-discoverer/page-details/reflecting-on-deepmind-s-alphafold-artificial-intelligence-success-what-s-the-real-significance-for-protein-folding-research-and-drug-discovery" class="uri">https://www.icr.ac.uk/blogs/the-drug-discoverer/page-details/reflecting-on-deepmind-s-alphafold-artificial-intelligence-success-what-s-the-real-significance-for-protein-folding-research-and-drug-discovery</a></p></li>
<li><p>A post that explain how Alphafold2 and RoseTTAfold code became publically available: <a href="https://www.wired.com/story/without-code-for-deepminds-protein-ai-this-lab-wrote-its-own/" class="uri">https://www.wired.com/story/without-code-for-deepminds-protein-ai-this-lab-wrote-its-own/</a></p></li>
</ul>
</section>
<section id="references" class="level1">
<h1>References</h1>



</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-al-janabi2022" class="csl-entry" role="doc-biblioentry">
Al-Janabi, Aisha. 2022. <span>“Has DeepMind’s AlphaFold Solved the Protein Folding Problem?”</span> <em>BioTechniques</em> 72 (3): 73–76. <a href="https://doi.org/10.2144/btn-2022-0007">https://doi.org/10.2144/btn-2022-0007</a>.
</div>
<div id="ref-baek2021" class="csl-entry" role="doc-biblioentry">
Baek, Minkyung, Frank DiMaio, Ivan Anishchenko, Justas Dauparas, Sergey Ovchinnikov, Gyu Rie Lee, Jue Wang, et al. 2021. <span>“Accurate prediction of protein structures and interactions using a three-track neural network.”</span> <em>Science (New York, N.Y.)</em> 373 (6557): 871–76. <a href="https://doi.org/10.1126/science.abj8754">https://doi.org/10.1126/science.abj8754</a>.
</div>
<div id="ref-bhattacharya2021" class="csl-entry" role="doc-biblioentry">
Bhattacharya, Sutanu, Rahmatullah Roche, Md Hossain Shuvo, and Debswapna Bhattacharya. 2021. <span>“Recent Advances in Protein Homology Detection Propelled by Inter-Residue Interaction Map Threading.”</span> <em>Frontiers in Molecular Biosciences</em> 8: 643752. <a href="https://doi.org/10.3389/fmolb.2021.643752">https://doi.org/10.3389/fmolb.2021.643752</a>.
</div>
<div id="ref-evans2022" class="csl-entry" role="doc-biblioentry">
Evans, Richard, Michael O’Neill, Alexander Pritzel, Natasha Antropova, Andrew Senior, Tim Green, Augustin Žídek, et al. 2022. <span>“Protein Complex Prediction with AlphaFold-Multimer.”</span> <a href="https://www.biorxiv.org/content/10.1101/2021.10.04.463034v2">https://www.biorxiv.org/content/10.1101/2021.10.04.463034v2</a>.
</div>
<div id="ref-holm2022" class="csl-entry" role="doc-biblioentry">
Holm, Liisa. 2022. <span>“Dali Server: Structural Unification of Protein Families.”</span> <em>Nucleic Acids Research</em> 50 (W1): W210–15. <a href="https://doi.org/10.1093/nar/gkac387">https://doi.org/10.1093/nar/gkac387</a>.
</div>
<div id="ref-jones2012" class="csl-entry" role="doc-biblioentry">
Jones, David T., Daniel W. A. Buchan, Domenico Cozzetto, and Massimiliano Pontil. 2012. <span>“PSICOV: precise structural contact prediction using sparse inverse covariance estimation on large multiple sequence alignments.”</span> <em>Bioinformatics (Oxford, England)</em> 28 (2): 184–90. <a href="https://doi.org/10.1093/bioinformatics/btr638">https://doi.org/10.1093/bioinformatics/btr638</a>.
</div>
<div id="ref-jones2015" class="csl-entry" role="doc-biblioentry">
Jones, David T., Tanya Singh, Tomasz Kosciolek, and Stuart Tetchner. 2015. <span>“MetaPSICOV: combining coevolution methods for accurate prediction of contacts and long range hydrogen bonding in proteins.”</span> <em>Bioinformatics (Oxford, England)</em> 31 (7): 999–1006. <a href="https://doi.org/10.1093/bioinformatics/btu791">https://doi.org/10.1093/bioinformatics/btu791</a>.
</div>
<div id="ref-jumper2021" class="csl-entry" role="doc-biblioentry">
Jumper, John, Richard Evans, Alexander Pritzel, Tim Green, Michael Figurnov, Olaf Ronneberger, Kathryn Tunyasuvunakool, et al. 2021. <span>“Highly Accurate Protein Structure Prediction with AlphaFold.”</span> <em>Nature</em> 596 (7873): 583–89. <a href="https://doi.org/10.1038/s41586-021-03819-2">https://doi.org/10.1038/s41586-021-03819-2</a>.
</div>
<div id="ref-kamisetty2013" class="csl-entry" role="doc-biblioentry">
Kamisetty, Hetunandan, Sergey Ovchinnikov, and David Baker. 2013. <span>“Assessing the utility of coevolution-based residue-residue contact predictions in a sequence- and structure-rich era.”</span> <em>Proceedings of the National Academy of Sciences of the United States of America</em> 110 (39): 15674–79. <a href="https://doi.org/10.1073/pnas.1314045110">https://doi.org/10.1073/pnas.1314045110</a>.
</div>
<div id="ref-kempen" class="csl-entry" role="doc-biblioentry">
Kempen, Michel van, Stephanie S. Kim, Charlotte Tumescheit, Milot Mirdita, Cameron L. M. Gilchrist, Johannes Söding, and Martin Steinegger. n.d. <span>“Foldseek: Fast and Accurate Protein Structure Search.”</span> <a href="https://doi.org/10.1101/2022.02.07.479398">https://doi.org/10.1101/2022.02.07.479398</a>.
</div>
<div id="ref-ma2015" class="csl-entry" role="doc-biblioentry">
Ma, Jianzhu, Sheng Wang, Zhiyong Wang, and Jinbo Xu. 2015. <span>“Protein contact prediction by integrating joint evolutionary coupling analysis and supervised learning.”</span> <em>Bioinformatics (Oxford, England)</em> 31 (21): 3506–13. <a href="https://doi.org/10.1093/bioinformatics/btv472">https://doi.org/10.1093/bioinformatics/btv472</a>.
</div>
<div id="ref-meier2015" class="csl-entry" role="doc-biblioentry">
Meier, Armin, and Johannes Söding. 2015. <span>“Automatic Prediction of Protein 3D Structures by Probabilistic Multi-template Homology Modeling.”</span> <em>PLoS computational biology</em> 11 (10): e1004343. <a href="https://doi.org/10.1371/journal.pcbi.1004343">https://doi.org/10.1371/journal.pcbi.1004343</a>.
</div>
<div id="ref-mirdita2022" class="csl-entry" role="doc-biblioentry">
Mirdita, Milot, Konstantin Schütze, Yoshitaka Moriwaki, Lim Heo, Sergey Ovchinnikov, and Martin Steinegger. 2022. <span>“ColabFold: making protein folding accessible to all.”</span> <em>Nature Methods</em> 19 (6): 679–82. <a href="https://doi.org/10.1038/s41592-022-01488-1">https://doi.org/10.1038/s41592-022-01488-1</a>.
</div>
<div id="ref-olmea1997" class="csl-entry" role="doc-biblioentry">
Olmea, O., and A. Valencia. 1997. <span>“Improving contact predictions by the combination of correlated mutations and other sources of sequence information.”</span> <em>Folding &amp; Design</em> 2 (3): S25–32. <a href="https://doi.org/10.1016/s1359-0278(97)00060-6">https://doi.org/10.1016/s1359-0278(97)00060-6</a>.
</div>
<div id="ref-outeiral" class="csl-entry" role="doc-biblioentry">
Outeiral, Carlos, Daniel A. Nissley, and Charlotte M. Deane. n.d. <span>“Current Protein Structure Predictors Do Not Produce Meaningful Folding Pathways.”</span> <a href="https://doi.org/10.1101/2021.09.20.461137">https://doi.org/10.1101/2021.09.20.461137</a>.
</div>
<div id="ref-pakhrin2021" class="csl-entry" role="doc-biblioentry">
Pakhrin, Subash C., Bikash Shrestha, Badri Adhikari, and Dukka B. Kc. 2021. <span>“Deep Learning-Based Advances in Protein Structure Prediction.”</span> <em>International Journal of Molecular Sciences</em> 22 (11): 5553. <a href="https://doi.org/10.3390/ijms22115553">https://doi.org/10.3390/ijms22115553</a>.
</div>
<div id="ref-pederson2021" class="csl-entry" role="doc-biblioentry">
Pederson, Thoru. 2021. <span>“Protein Structure: Has Levinthal’s Paradox <span>“</span>Folded<span>”</span>?”</span> <em>The FASEB Journal</em> 35 (3): e21416. <a href="https://doi.org/10.1096/fj.202100136">https://doi.org/10.1096/fj.202100136</a>.
</div>
<div id="ref-peng2011" class="csl-entry" role="doc-biblioentry">
Peng, Jian, and Jinbo Xu. 2011. <span>“A Multiple-Template Approach to Protein Threading.”</span> <em>Proteins: Structure, Function, and Bioinformatics</em> 79 (6): 1930–39. <a href="https://doi.org/10.1002/prot.23016">https://doi.org/10.1002/prot.23016</a>.
</div>
<div id="ref-porta-pardo2022" class="csl-entry" role="doc-biblioentry">
Porta-Pardo, Eduard, Victoria Ruiz-Serra, Samuel Valentini, and Alfonso Valencia. 2022. <span>“The Structural Coverage of the Human Proteome Before and After AlphaFold.”</span> <em>PLOS Computational Biology</em> 18 (1): e1009818. <a href="https://doi.org/10.1371/journal.pcbi.1009818">https://doi.org/10.1371/journal.pcbi.1009818</a>.
</div>
<div id="ref-roy2010" class="csl-entry" role="doc-biblioentry">
Roy, A., A. Kucukural, and Y. Zhang. 2010. <span>“I-TASSER: a unified platform for automated protein structure and function prediction.”</span> <em>Nat Protoc</em> 5 (4): 725–38. <a href="https://doi.org/nprot.2010.5 [pii] 10.1038/nprot.2010.5">https://doi.org/nprot.2010.5 [pii] 10.1038/nprot.2010.5</a>.
</div>
<div id="ref-senior2020" class="csl-entry" role="doc-biblioentry">
Senior, Andrew W., Richard Evans, John Jumper, James Kirkpatrick, Laurent Sifre, Tim Green, Chongli Qin, et al. 2020. <span>“Improved protein structure prediction using potentials from deep learning.”</span> <em>Nature</em> 577 (7792): 706–10. <a href="https://doi.org/10.1038/s41586-019-1923-7">https://doi.org/10.1038/s41586-019-1923-7</a>.
</div>
<div id="ref-varadi2022" class="csl-entry" role="doc-biblioentry">
Varadi, Mihaly, Stephen Anyango, Mandar Deshpande, Sreenath Nair, Cindy Natassia, Galabina Yordanova, David Yuan, et al. 2022. <span>“AlphaFold Protein Structure Database: Massively Expanding the Structural Coverage of Protein-Sequence Space with High-Accuracy Models.”</span> <em>Nucleic Acids Research</em> 50 (D1): D439–44. <a href="https://doi.org/10.1093/nar/gkab1061">https://doi.org/10.1093/nar/gkab1061</a>.
</div>
<div id="ref-yang2020" class="csl-entry" role="doc-biblioentry">
Yang, Jianyi, Ivan Anishchenko, Hahnbeom Park, Zhenling Peng, Sergey Ovchinnikov, and David Baker. 2020. <span>“Improved Protein Structure Prediction Using Predicted Interresidue Orientations.”</span> <em>Proceedings of the National Academy of Sciences</em> 117 (3): 1496–1503. <a href="https://doi.org/10.1073/pnas.1914677117">https://doi.org/10.1073/pnas.1914677117</a>.
</div>
<div id="ref-zheng2021" class="csl-entry" role="doc-biblioentry">
Zheng, Wei, Chengxin Zhang, Yang Li, Robin Pearce, Eric W. Bell, and Yang Zhang. 2021. <span>“Folding non-homologous proteins by coupling deep-learning contact maps with I-TASSER assembly simulations.”</span> <em>Cell Reports Methods</em> 1 (3): 100014. <a href="https://doi.org/10.1016/j.crmeth.2021.100014">https://doi.org/10.1016/j.crmeth.2021.100014</a>.
</div>
</div></section><section class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1" role="doc-endnote"><p>https://www.bbc.com/news/science-environment-57929095</p>
<p>https://www.forbes.com/sites/robtoews/2021/10/03/alphafold-is-the-most-important-achievement-in-ai-ever/</p>
<p>https://elpais.com/ciencia/2021-07-22/la-forma-de-los-ladrillos-basicos-de-la-vida-abre-una-nueva-era-en-la-ciencia.html<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
    var links = window.document.querySelectorAll('a:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // target, if specified
          link.setAttribute("target", "_blank");
          // default icon
          link.classList.add("external");
      }
    }
});
</script>
</div> <!-- /content -->



</body></html>
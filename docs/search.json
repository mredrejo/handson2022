[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hands-on introduction to Protein Modeling",
    "section": "",
    "text": "This brief instruction booklet contains the materials for the “Hands-on Protein Modeling” sessions at the CIVIS Summer School Bioinformatics for non-bioinformaticians, Tübingen, Germany (18-22 July 2022). This is a Quarto book. All this material is open access and it is shared under CC BY-NC license.\n\n\n\nLink to the website of the Master’s Degree in Bioinformatics & Computational Biology at UAM\n\n\nMost of the materials are shared with the course Structural Bioinformatics that I lecture in the Master’s Degree in Bioinformatics & Computational Biology @UAM.\nAt the end of each section there are several questions highlighted in green that pretend to motivate you to think about the acquired knowledge and skills and go a little bit forward in the interpretation of the results.\nThe contents of this short course are also largely inspired in the works of others that shared their course materials, tips and other kind of resources on their own websites, GitHub or Twitter, including Alexandre Bovin, Sergey Ovchinnikov, Martin Steinegger, Carlos Outeiral, among many others. I tried to acknowledge (and link!) each one of those contributions but I’d like to apologize beforehand for those that I may have not mention.\nAs a suggestion, I would like to invite you to check the set of exercises on Structural Bioinformatics from the Pontificia Universidad Católica de Chile, described in Engelberger et al. (2021): https://github.com/pb3lab/ibm3202\n\n\nPlease let me know if you find some mistake missing reference. Definitely, I’ll appreciate any suggestion or correction. You can reach me by email or  Twitter."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Introduction",
    "section": "",
    "text": "Structural Bioinformatics is a broad discipline that covers structural and computational biology, from visualization and analysis of the structure of biomacromolecules to protein modeling and molecular docking. Powered by great technical advances, the field has experienced a great revolution in the last decade. The increase of experimental capacities to analyze the structure of proteins and other biological molecules and structures (see Callaway (2020)) and the development of Artificial Intelligence (AI)-assisted structure prediction boosted the capacity of life-science researchers to address a wide variety of questions regarding proteins diversity, evolution and function. The implications of this revolution in biology, biotechnology, and biomedicine are still unforeseen.\n\nFor a short introductory course on protein modeling, I propose the following three basic objectives:\n\nIdentify the main applications and limitations of the prediction of protein structures in biomedicine and biotechnology.\nBecome familiar with classic and state-of-the-art protein modeling methods.\nBasic understanding of the resulting output of a protein modeling experiment and how to evaluate and eventually improve the model quality."
  },
  {
    "objectID": "intro.html#warning-for-future-structural-biologists",
    "href": "intro.html#warning-for-future-structural-biologists",
    "title": "Introduction",
    "section": "Warning for future structural biologists",
    "text": "Warning for future structural biologists\n\n\n\nCeci n’est pas une proteine. Source: https://swissmodel.expasy.org/static/course/files/PartIII_quality_assesment.pdf\n\n\nThe surrealist Belgian painter René Magritte created a collection of surrealistic paintings entitled La trahison des images (1928–1929). The most renowned of those paintings show a smoking pipe and the following caption underneath: “Ceci n’est pas une pipe” (This is not a pipe). Yes, indeed! It is actually the painting of a pipe.\nSimilarly, a picture of a protein, or a PDB file with the coordinates of a protein structure, is not a protein. It is a representation of ONE structure. Even experimentally determined structures have two main limitations that we should always keep in mind: (1) they are a fixed structure whereas proteins in vivo are flexible and dynamic and (2) they are subjected to experimental error and they often contain regions of low reliability. Moreover, even experimentally obtained macromolecular structures are to some degree models, with a variable ratio between experimental data and computational prediction to match the experimental data (X-ray diffraction, cryo-EM density maps, NMR, SAXS, FRET…) with previously known structures or prediction models. That does not mean that protein structures are useless, they can be very useful, but we must be aware of the limitations as well as the applications."
  },
  {
    "objectID": "homology.html",
    "href": "homology.html",
    "title": "Homology Modeling",
    "section": "",
    "text": "The number of protein sequences in databases growth exponentially during the last decades, particularly after the revolution of high throughput sequencing methods.\n\n\n\nNumber of entries in UniProt/TrEMBL (release 2022_2).\n\n\nHowever, experimental determination of 3D protein structures is often difficult, time-consuming, and subjected to limitations, such as experimental error, data interpretation and modeling new data on previously released structures. Thus, despite substantial efforts that started at the beginning of the 21st century to implement high-throughput structural biology methods (see for instance Manjasetty et al. 2008), the availability of protein structures is more than 1,000 times less than the number of sequences (231,354,261 sequences for Uniprot and 192,489 structures in RCSB Protein Databank in 2022). This difference is called the protein structure gap and it is constantly widening (Muhammed and Aki-Yalcin 2019).\n\n\n\nNumber of macromolecular structures in RCSB PDB database (accessed 6th July 2022).\n\n\nThus, an accurate prediction of the 3D structure of any given protein is needed to make up for the lack of experimental data.\n\n\nAmino acid properties determine the phi and psi angles that eventually shape the higher structural levels. Protein folding might be more complex though, as it should be coupled to protein synthesis.\nIn 1968, Cyrus Levinthal (1922–1990) published the so-called Levinthal’s paradox, stating that proteins fold in nano/milliseconds, but even for small peptides it will take a huge time to test the astronomical number of possible conformations. Say a 100 aa small protein; it will have 99 peptidic bonds and 198 different phi and psi angles. Assuming only 3 alternative conformations for each bond, it will yield 3198 (= 2.95 x 1095) possible conformations. If we design a highly efficient algorithm that tests 1 conformation per nanosecond:\n 2.95 x 1085 secs = 9x1067 billions years\nConsidering that the age of the universe is 13.8 billion years, predicting protein structures does not seem an easy task.\nIn this context, roughly 50 years ago, a very simple experiment led some light on the protein folding mechanism. Cristian Anfisen was able to completely denature (unfold) the Ribonuclease A, by the addition of reducing agents and urea under heat treatment, and subsequently switch to normal conditions that allow the protein to re-fold fully functional. This experiment indicates that the amino acid sequence dictates the final structure. Notwithstanding some relevant exceptions, this has been largely confirmed.\n\n\n\n\n\nThe Anfinsen Dogma: Amino acid sequence dictated the final structure. From Anfinsen (1973) .\n\n\nOne can imagine that in vivo native structures of proteins look-alike the lowest free energy conformation, i.e., the global energy minimum. That is the basis of the funnel model of protein folding, which assumes that the number of possible conformations is reduced when a local energy minimum is achieved, constituting a path for the folding process.\n\n\n\nSchematic diagram of a protein folding energy landscape according to the funnel model. Denatured molecules at the top of the funnel might fold to the native state by a myriad of different routes, some of which involve transient intermediates (local energy minima) whereas others involve significant kinetic traps (misfolded states). From .\n\n\nIn conclusion, prediction of protein structures is possible, as protein folding relies only on the protein sequence, but it will require virtually infinite time and computational resources.\nHomology modeling is one of the easiest tricks to bypass that limitation. Basically, the strategy is adding all the possible extra information to the amino acid properties, namely the evolutionary conservation of sequences and structures.\nVery often, before generating models you already have some information about your protein. For instance, if it is an enzyme you may have spotted the catalytic residues or substrate-interaction region. It is also advisable to check the literature, particularly if there is a companion paper of the related PDB structure(s) that may be available or that you can eventually find and use as the template(s) for modeling."
  },
  {
    "objectID": "homology.html#step-12.-template-search-and-align.",
    "href": "homology.html#step-12.-template-search-and-align.",
    "title": "Homology Modeling",
    "section": "3.1 Step 1+2. Template search and align.",
    "text": "3.1 Step 1+2. Template search and align.\n\n3.1.0.1 Where can we search?\nTemplate searching consists in finding a protein with known structure that has a sequence similar to our protein. As we mentioned above, the RCSB Protein Data Bank (PDB) is the largest database of protein structures, so we can search templates by comparing the sequence of our protein with the sequence of all the proteins in PDB. However, PDB was constructed to contain all the macromolecular structures, not for searching templates for modeling. Similar to other end-to-end software, SWISS-MODEL has its own curated database, called SMLT (SWISS-MODEL template library). This is based on PDB, updated weekly, and also annotated and indexed to boost searches. As of 6 July 2022, SMLT contains 133,049 unique protein sequences that map to 332,864 biological units (protein structures classified by their quaternary structure).\nNow, you first need your sequences. A protein sequence database like Uniprot or NCBI Protein, is a good place for this task.\nIf you want to cheat yourself, I give you the HAdV-2pol and NEIL2 sequences.\n\n\n3.1.0.2 How can we search accurately and fast?\n\n\n\n\n\nQuery-template alignment is the base for homology modeling (Kelley (2009a))\n\n\nFinding templates require comparing sequences, thus an accurate and powerful alignment method is essential. Comparing one protein sequence with a whole database is time-consuming, as you will compare with totally unrelated proteins, which is a loss of resources. Two basic improvements increased the template search capacity, (1) the introduction of secondary structure (SS) by comparing SS predictions of the query protein and the secondary structures of the protein database, and (2) the use of profiles to make easier the comparison. Profiles are a mathematical way to summarize a multiple sequence alignment in which the frequency of each amino acid at each position is quantified. This allows the identification of highly conserved positions that not only define the protein function but also the fold. For instance, glycines at the end of each beta-strand or a pattern of polar residues that favor alpha-helices. A previous comparison of the query sequence with a database of sequences will allow us to include evolutionary information about it. Therefore, we moved from a requirement of >30% identity to obtain good models before the implementation of profiles, to good models even with ⁓20% identity or below. Moreover, the generation of profiles also facilitates clustering of the search database, reducing search time. The implementation of these capacities led to the implementation of the so-called fold recognition in homology modeling.\n\n\n\n\n\nFrom sequence vs. sequence search to profile-profile comparison (Kelley (2009b))\n\n\nTemplate searches in SWISS-MODEL are carried out with HHblits (Remmert et al. (2011)), a specific profile-profile method. We could search for templates also with Blast or other profile-profile methods, like Psi-BLAST, HHPred, or JackHMMER. Then templates are ranked by two different parameters, GMQE (global model quality estimate) and QSQE (quaternary structure quality estimate). Briefly, GMQE uses probability functions to assess several properties of the target-template alignment (sequence identity, sequence similarity, HHblits score, the agreement between predicted secondary structure of target and template, the agreement between predicted solvent accessibility between target and template; all normalized by alignment length) to predict the expected quality of the resulting model. QSQE assesses the oligomeric state probability of the model.\nNow, paste your sequences and click on Search.\nNote: If you click on “Build Model”, it will directly use the top-ranked template, so you’ll miss some fun, but you can go back for that later on if you change your mind.\n\n\n\nSWISS-MODEL modeling start\n\n\nBefore building the models, could you foresee which of our queries will give rise to a better model? Why?"
  },
  {
    "objectID": "homology.html#step-3.-model-building.",
    "href": "homology.html#step-3.-model-building.",
    "title": "Homology Modeling",
    "section": "3.2 Step 3. Model Building.",
    "text": "3.2 Step 3. Model Building.\nBy default, SWISS-MODEL will provide 50 ranked possible templates. The output also contains information about the method and resolution of the templates, the % of identity (and alignment coverage) with the query sequence, and the GMQE and QSQE.\nThe top template is marked by default and it likely will give the best model, but it is also interesting to try some alternative templates depending on the downstream application of the model (see below). For instance with a different substrate/cofactor that can have a key role in the protein function or with different coverage or % identity.\nOnce the template(s) is selected, model coordinates are constructed based on the alignment of the query and template sequence. SWISS-MODEL uses a fragment assembly, as well as RosettaCM, another very well-known homology modeling algorithm by the Baker lab, implemented in Rosetta software and the Robetta server. Other programs, like Modeller, are based in the satisfaction of spatial restraints (Janson et al. 2019).\nFragment assembly will use the template core backbone atoms to build a core structure of the model, leaving non-conserved regions (mostly loops) for later. Then, it will find compatible fragments in a dedicated loop database and also use ab initio building or missing loops.\n\n\n\nBackbone and loop modeling. From Expasy Protein Structure, Comparative Protein Modelling, and Visualisation.\n\n\nThen, side chain of non conserved amino acids in undertook. The goal is findig the most likely side chain conformation, using template structure information, rotamer libraries (from known protein structures) and energetic and packaging criteria. If many side chains have to be placed in the structure it will lead to a “chicken and egg problem”. Thus, the more residues correctly positioned, the best model. That means that identification of hydrogen bonds between residues side chains and between side chains and the backbone reduce the optimization calculations.\n\n\n\nSide chain modeling. From CMBI Seminars on Bioinformatics\n\n\nFinally, a short energy minimization is carry out to reduce the unfavorable contacts and bonds by adapting the angle geometries and relax close contacts. This energy minimization step or refinement can be useful to achieve better models but only when the folding is already accurate."
  },
  {
    "objectID": "homology.html#step-4.-result-assessing.",
    "href": "homology.html#step-4.-result-assessing.",
    "title": "Homology Modeling",
    "section": "3.3 Step 4. Result assessing.",
    "text": "3.3 Step 4. Result assessing.\nOutput models are colored in a temperature color scale, from navy blue (good quality) to red (bad quality). That can help us to understand our model in a first sight. Also, this is an interactive site and you can zoom-in, zoom-out the model. Many other features are available to work on your model. For instance, you can compare multiple models, you can change the display options. You can also download all the files and reports on the “Project Data” button.\n\n\n\nNEIL2 model created with SWISS-MODEL (July 2022)\n\n\nThere is also a “Structure Assessment” option. This provide you a detailed report of the structural problems of your model. You can see Ramachandran plots that highlight in red the amino acid residues with abnormal phi/psi angles in the model and a detailed list of other problems.\nThe GMQE is updated to the QMEAN Zscore and QMEANDisCo (Studer et al. 2020). The QMEAN Z-score or the normalized QMEAN score indicates how the model is comparable to experimental structures of similar size. A QMEAN Z-score around 0 indicates good agreement, while score below -4.0 are given to models of low quality. Besides the number, a plot shows the QMEAN score of our model (red star) within all QMEAN scores of experimentally determined structures compared to their size. Overall, the Z-score is equivalent to the standard deviation of the mean.\nThe QMEANDisCO is a single parameter that combines statistical potentials and agreement terms with a distance constraints (DisCo) to provide a consensus score. DisCo evaluates consistencies of pairwise CA-CA distances from a model with constraints extracted from homologous structures. All scores are combined using a neural network trained to predict per-residue scores.\n\n\n\nHAdV-2 DNA polymerase model obtained with SWISS-MODEL.\n\n\nQMEANDisCo can be used to analyze models obtained with other methods in order to make them comparable. There are other model assessing tools commonly used to assess protein models, like MoldFold (McGuffin et al. 2021) or VoroMQA (Olechnovič and Venclovas 2017).\nAnother key parameter that you should know if you want to compare protein strutures is the alpha carbon RMSD (root mean square deviation of the alpha carbons), sometimes referred in the protein field only as as RMSD. Any protein structural alignment will give you this parameter as an estimation of the difference of the structures. You can align structure with many online servers, like FATCAT2 or using molecular visualization apps, like ChimeraX or Pymol (also available here).\nWhich model is better? Which regions are more difficult to model? Why?"
  },
  {
    "objectID": "homology.html#corollary",
    "href": "homology.html#corollary",
    "title": "Homology Modeling",
    "section": "3.4 Corollary: What can I do with my model and what I cannot?",
    "text": "3.4 Corollary: What can I do with my model and what I cannot?\n\n\n\nAccuracy and application of protein structure models. From .\n\n\nA big power entails a big responsibility. The use of models entails a precaution and a need for experimental validation. However, knowing the limitations of our model is required for a realist use of it; and limits are defined by the model quality.\nThe accuracy of a comparative model is related to the percentage sequence identity on which it is based. High-accuracy comparative models can have about 1-2 Å root mean square (RMS) error for the main-chain atoms, which is comparable to the accuracy of a nuclear magnetic resonance (NMR) structure or an x-ray structure. These models can be used for functional studies and the prediction of protein partners, including drugs or other proteins working in the same process. Also, for some detailed studies, it would be convenient to refine your model by Molecular Dynamics and related methods towards a native-like structure. I suggest checking the review by Adiyaman and McGuffin (2019) on this topic.\nOn the contrary, low-accuracy comparative models are based on less than 20-30% sequence identity, hindering the modeling capacity and accuracy. Some of these models can be used for protein engineering purposes or to predict the function of orphan sequences based on the protein fold (using Dali or Foldseek).\nAs mentioned above, it also advisable to check the template structures and read the papers describing them in order to squeeze all the information from your model.\nWhat do you think you could use our models of NEIL2 and HAdV-2pol?"
  },
  {
    "objectID": "homology.html#template",
    "href": "homology.html#template",
    "title": "Homology Modeling",
    "section": "3.1 Step 1+2. Template search and align.",
    "text": "3.1 Step 1+2. Template search and align.\n\n3.1.0.1 Where can we search?\nTemplate searching consists in finding a protein with known structure that has a sequence similar to our protein. As we mentioned above, the RCSB Protein Data Bank (PDB) is the largest database of protein structures, so we can search templates by comparing the sequence of our protein with the sequence of all the proteins in PDB. However, PDB was constructed to contain all the macromolecular structures, not for searching templates for modeling. Similar to other end-to-end software, SWISS-MODEL has its own curated database, called SMLT (SWISS-MODEL template library). This is based on PDB, updated weekly, and also annotated and indexed to boost searches. As of 6 July 2022, SMLT contains 133,049 unique protein sequences that map to 332,864 biological units (protein structures classified by their quaternary structure).\nNow, you first need your sequences. A protein sequence database like Uniprot or NCBI Protein, is a good place for this task.\nIf you want to cheat yourself, I give you the HAdV-2pol and NEIL2 sequences.\n\n\n3.1.0.2 How can we search accurately and fast?\n\n\n\n\n\nQuery-template alignment is the base for homology modeling (Kelley 2009)\n\n\nFinding templates require comparing sequences, thus an accurate and powerful alignment method is essential. Comparing one protein sequence with a whole database is time-consuming, as you will compare with totally unrelated proteins, which is a loss of resources. Two basic improvements increased the template search capacity, (1) the introduction of secondary structure (SS) by comparing SS predictions of the query protein and the secondary structures of the protein database, and (2) the use of profiles to make easier the comparison. Profiles are a mathematical way to summarize a multiple sequence alignment in which the frequency of each amino acid at each position is quantified. A particular type of profiles, the Hidden Markov Models (HMM) are very well suited to search databases for similar sequences. HMMs include amino acid insertions and deletions, meaning that they can model entire alignments, including divergent regions. This allows the identification of highly conserved positions that not only define the protein function but also the fold. For instance, glycine residues at the end of each beta-strand or a pattern of polar residues that favors alpha-helices. A previous comparison of the query sequence with a database of sequences will allow us to include evolutionary information about it. Therefore, we moved from a requirement of >30% identity to obtain good models before the implementation of profiles, to good models even with ⁓20% identity or below. Moreover, the generation of profiles also facilitates clustering of the search database, reducing search time. The implementation of these capacities led to the implementation of the so-called fold recognition in homology modeling.\n\n\n\n\n\nFrom sequence vs. sequence search to profile-profile comparison (Kelley 2009).\n\n\nTemplate searches in SWISS-MODEL are carried out with HHblits (Remmert et al. 2011), a specific profile-profile method. We could search for templates also with Blast or other profile-profile methods, like Psi-BLAST, HHPred, or JackHMMER. Then templates are ranked by two different numeric parameters ranged between 0 and 1: GMQE (global model quality estimate) and QSQE (quaternary structure quality estimate). Briefly, GMQE uses probability functions to assess several properties of the target-template alignment (sequence identity, sequence similarity, HHblits score, the agreement between predicted secondary structure of target and template, the agreement between predicted solvent accessibility between target and template; all normalized by alignment length) to predict the expected quality of the resulting model. QSQE assesses the oligomeric state probability of the model.\nNow, paste your sequences and click on Search.\nNote: If you click on “Build Model”, it will directly use the top-ranked template, so you’ll miss some fun, but you can go back for that later on if you change your mind.\n\n\n\nSWISS-MODEL modeling start\n\n\nBefore building the models, could you foresee which of our queries will give rise to a better model? Why?"
  },
  {
    "objectID": "ai.html",
    "href": "ai.html",
    "title": "AI-based protein modeling with Colabfold",
    "section": "",
    "text": "As mentioned earlier, the introduction of HMM-based profiles during the first decade of this century led to a great improvement in template detection and protein modeling in the twilight-zone, i.e., proteins with only distant homologs (<25-30% identity) in databases. These methods naturally evolved to iterative threading methods, based on multitemplate model construction, implemented in I-tasser (Roy, Kucukural, and Zhang 2010), RaptorX (Peng and Xu 2011) and HHpred (Meier and Söding 2015), among others.\n\n\n\n\n\nContact-based map of representative proteins. The map represents a matrix of amino acid positions in the protein sequences (on both, the X and Y axis); with contacts indicated as blue dots. When a number of consecutive residues in the sequence interact the dots form diagonal stretches. Maps obtained at http://cmweb.enzim.hu/\n\n\nDuring the last decade, the introduction of residue-residue contact or distance maps prediction based on sequence co-evolution and deep learning started a revolution in the field that crystallize with the arrival of Alphafold2 and RoseTTAfold as major breakthroughs with great repercussions in diverse fields.\n\n\n\nSchematic of how co-evolution methods extract information about protein structure from a multiple sequence alignment (MSA). Image modified from doi: 10.5281/zenodo.1405369, which in turn was modified from doi: 10.1371/journal.pone.0028766\n\n\nAs shown in the picture below, residue contact maps are a 2D matrix-like representation of the protein sequence in which each pair of interacting residues are indicated. An accurate information of protein’s residue–residue contacts is sufficient to elucidate the fold of a protein Olmea and Valencia (1997), however obtaining this map is not always easy. The introduction of evolutionary coupling analysis (ECA), i.e., extract the residue coevolution from MSAs (piture above) improved contact maps and allowed their implementation for protein folding in several methods, like PSICOV (Jones et al. 2012) or Gremlin (Kamisetty, Ovchinnikov, and Baker 2013), among others. However, for proteins without many sequence homologs, the predicted contacts were of low quality and insufficient for accurate contact-assisted protein modeling.\n\n\n\nIllustration of column pair and precision submatrix grouping for advanced prediction of contact maps. In the example, Columns 5 and 14 in the first family are aligned to columns 5 and 11 in the second family, respectively, so column pair (5,14) in the first family and the pair (5,11) in the second family are assigned to the same group. Accordingly, the two precision submatrices will be asigned to the same group. From Ma et al. (2015).\n\n\nDeep learning is a sub-field of machine learning which is based on artificial neural networks. Neural networks were introduced actually in the late 40’s and 50’s, but they reappeared in the 2000’s thanks to the increase of computational capacities and the use of GPUs. Briefly, a NN uses multiple interconnected layers to transform multiple inputs (MSAs, high-resolution contact based maps…) into compound features that can be used to predict a complex output, like a 3D protein structure. As their name indicate, NNs attempt to simulate the behavior of the human brain that process large amounts of data and can be trained to “learn” from that data. Deep learning is based in the use of multiple layer-NN to optimize and refine for accuracy.\nIn this context, introduction of supervised machine learning methods that predict contacts from distant protein families, outperforming ECA methods by the use of multilayer neural networks [Jones et al. (2015), Ma et al. (2015)]. This methods also benefit from the use of the so-called high resolution contact maps, that contained not only contact information, but also distances and angles.\n\n\n\n\n\nHigh-resolution contact maps of 6MSP. From Yang et al. (2020)\n\n\n\n\nEvery two years since 1994, structural bioinformatics groups carry out a worldwide experiment, predicting a set of unknown protein structures in a controlled competition and comparing their output with the experimentally obtained structure. This is the CASP or Critical assessment of Protein Structure Prediction.\n\n\n\nComparative z-core of CASP13 participants. The score is based in the GDT_TS (Global distance test).\n\n\nThe best research groups in the field test their new methods and protocols in CASP. However, in CASP13 (2018) an AI company called Deepmind (Google Subsidiary) entered in the scene. Their method, named Alphafold (Senior et al. 2020) clearly won CASP13. Bassically, Alphafold implemented some improvements in recently used approaches, creating a new whole pipeline. Instead of create contact maps from the alingment to fold the structure they used a MRF unit (Markov Random Field) to extract in advance the main features of the MSA and process into a multilayer NN called ResNet that provide the distant map and other information that you can use to create the structure and then improve it by energy minimization and substitution of portions with a selected DB of protein fragments.\n\n\n\nWorkflow of the first Alphafold method presented in CASP13. MSA stands for multiple sequence alignment; PSSM indicates Position-specific-scoring matrix and MRF stands for Markov Random Field (or Potts model). From the Sergei Ovchinnikov and Martin Steinegger presentation of Alphafold2 to the Boston Protein Design Group (link below)\n\n\nAfter Alphafold, similar methods were also developed and made available to the general public, like the trRosetta from Baker lab (Yang et al. 2020), available in the Robetta server. This led to some controversy (mostly on Twitter) about the open access to the CASP software and later on DeepMind publishes all the code on GitHub."
  },
  {
    "objectID": "ai.html#useful-links",
    "href": "ai.html#useful-links",
    "title": "AI-based protein modeling with Colabfold",
    "section": "Useful links",
    "text": "Useful links\n\nIntroductory article to Neural Networks at the IBM site: https://www.ibm.com/cloud/learn/neural-networks\nColabFold Tutorial presented presented by Sergey Ovchinnikov and Martin Steineggerat the Boston Protein Design and Modeling Club (6 ago 2021). [video] [slides].\nPost about Alphafold2 in the Oxford Protein Informatics Group site: https://www.blopig.com/blog/2021/07/alphafold-2-is-here-whats-behind-the-structure-prediction-miracle/\nA very good digest article about the Alphafold2 paper: https://moalquraishi.wordpress.com/2021/07/25/the-alphafold2-method-paper-a-fount-of-good-ideas/"
  },
  {
    "objectID": "ai.html#why-is-alphafold2-so-accurate",
    "href": "ai.html#why-is-alphafold2-so-accurate",
    "title": "AI-based protein modeling with Colabfold",
    "section": "Why is Alphafold2 so accurate?",
    "text": "Why is Alphafold2 so accurate?\nThe phylosophy behind Alphafold and Alphafold2 is treating protein folding problem as a machine learning problem of processing of images. In all these problems, the input to the Deep Learning model is a volume (3D tensor). In case of computer vision, 2D images expand as a volume because of the RGB or HSV channels. Similarly, in the case of distance prediction, predicted 1D and 2D features are transformed and packed into 3D volume with many channels of inter-residue information (Pakhrin et al. 2021).\n\n\n\nFrom the perspective of Deep Learning method development, the problem of protein distogram or real-valued distance prediction (bottom row) is similar to the ‘depth prediction problem’ in computer vision. From (Pakhrin et al. 2021)\n\n\nAlphafold2 can be explained in three independent tasks (see picture below). First, it queries several databases of protein sequences, and constructs an MSA that is used to select templates. In the second part of the diagram, AlphaFold 2 takes the multiple sequence alignment and the templates, and processess them in a transformer. The objective of this part is to extract layers of information to generate residue interaction maps. A better model of the MSA will improve the network’s characterization of the geometry, which simultaneously will help refine the model of the MSA. Importantly, this process is iterative and the number of recycling steps improve the model (the original model uses 48 blocks of cycles).\nThe third part of the pipeline is the structure building module, which use the information from the previous steps to construct a 3D model structure protein of the query sequence. This network will give you a single model, without any energy optimization step.\n\n\n\nOxford Proteins Informatics Group Blog, modified From (Jumper et al. 2021b)\n\n\nAs mentioned above, Colabfold aims to make the process faster by using MMSeqs in the first block. Additionally, the number of recycling steps can also adapated."
  },
  {
    "objectID": "ai.html#corollary-has-levinthals-paradox-folded",
    "href": "ai.html#corollary-has-levinthals-paradox-folded",
    "title": "AI-based protein modeling with Colabfold",
    "section": "Corollary: Has Levinthal’s paradox “folded”?",
    "text": "Corollary: Has Levinthal’s paradox “folded”?\nThe development of Alphafold and the Alphafold structures Database in collaboration with EMBL-EBI has been the origin of a New Era. Scientific publications and journals worldwide published long articles about the meaning of this breakthrough in science and its applications in biotechnology and biomedicine1 and DeepMind claimed to have Solved a 50-years Grand Challenge in biochemistry. The coverage of the protein structure space has been greatly increased (Porta-Pardo et al. 2022).\nHowever, some scientists have claimed that Alphafold2 and RoseTTAfold actually “cheat” a bit as it does not really solve the problem but generate a deep learning pipeline that “bypass” the problem (Pederson 2021). In agreement with that, it has been shown that machine learning methods actually do not reproduce the expected folding pathways while improving the structures during the recycling steps Outeiral, Nissley, and Deane (n.d.).\nIn conclusion, I do believe that Levinthal’s paradox has not been (yet) fully solved, but almost, and solving it will probably reduce the limitations of Alphafold2. However, CASP15 is currently being held and maybe I will have to change my mind later this year."
  },
  {
    "objectID": "ai.html#why-is-alphafold2-so-freaking-accurate",
    "href": "ai.html#why-is-alphafold2-so-freaking-accurate",
    "title": "AI-based protein modeling with Colabfold",
    "section": "Why is Alphafold2 so freaking accurate?",
    "text": "Why is Alphafold2 so freaking accurate?\nThe philosophy behind Alphafold and Alphafold2 is treating the protein folding problem as a machine learning problem of image processing. In all these problems, the input to the Deep Learning model is a volume (3D tensor). In the case of computer vision, 2D images expand as a volume because of the RGB or HSV channels. Similarly, in the case of distance prediction, predicted 1D and 2D features are transformed and packed into 3D volume with many channels of inter-residue information (Pakhrin et al. 2021).\n\n\n\nFrom the perspective of Deep Learning method development, the problem of protein distogram or real-valued distance prediction (bottom row) is similar to the ‘depth prediction problem’ in computer vision. From\n\n\nAlphafold2 can be explained in three independent tasks (see picture below). First, it queries several databases of protein sequences and constructs an MSA that is used to select templates. In the second part of the diagram, AlphaFold 2 takes the multiple sequence alignment and the templates, and processes them in a transformer. The objective of this part is to extract layers of information to generate residue interaction maps. A better model of the MSA will improve the network’s characterization of the geometry, which simultaneously will help refine the model of the MSA. Importantly, this process is iterative and the number of recycling steps improves the model (the original model uses 48 blocks of cycles).\nThe third part of the pipeline is the structure building module, which uses the information from the previous steps to construct a 3D model structure protein of the query sequence. This network will give you a single model, without any energy optimization step.\n\n\n\nOxford Proteins Informatics Group Blog, modified From\n\n\nAs mentioned above, Colabfold aims to make the process faster by using MMSeqs in the first block. Additionally, the number of recycling steps can also be adapted. Moreover, different Colabfold notebooks have been developed (and evolved) to allow some customization and other feature, like batch processing of multiple proteins and identification of protein-protein interactions (Mirdita et al. 2022).\n\nProtein modeling methods based on inter-residue interaction map threading using deep learning\n\n\nMethod\nReference(s)\nLink\n\n\n\n\nRaptorX -contact\nWang et al. (2017)\nhttp://raptorx.uchicago.edu/ContactMap/\n\n\nCE-threader\nZheng et al. (2019)\nhttps://zhanggroup.org/CEthreader/\n\n\nDisCovEr\nBhattacharya et al. (2022)\nhttps://github.com/Bhattacharya-Lab/DisCovER\n\n\ntrRosetta\nYang et al. (2020)\nhttps://robetta.bakerlab.org/\n\n\nAlphafold\nSenior et al. (2020)\n<https://github.com/deepm ind/deepmind-research/tree/master/alphafold_casp13aa>\n\n\nRoseTTAfold\nBaek et al. (2021)\nhttps://robetta.bakerlab.org/\n\n\nAlphafold2\nJumper et al. (2021)\n& Mirdita et al. (2022)\nhttps://git hub.com/deepmind/alphafold\nhttps://github.com/sokrypton/ColabFold\n\n\nC-I-Tasser\nZheng et al. (2021)\nhttps://zhanggroup.org/C-I-TASSER/"
  },
  {
    "objectID": "ai.html#lets-try-alphafold2.",
    "href": "ai.html#lets-try-alphafold2.",
    "title": "AI-based protein modeling with Colabfold",
    "section": "Let’s try Alphafold2.",
    "text": "Let’s try Alphafold2.\nSection under construction!"
  }
]